{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c566eb6e",
   "metadata": {},
   "source": [
    "# Data segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd ..\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.patches as patches\n",
    "from skimage.segmentation import morphological_chan_vese\n",
    "\n",
    "array_segmented_images = np.load(r\"./data/segmentation.npy\")\n",
    "array_data_cropped = np.load('./temp/array_data_cropped.npy')\n",
    "\n",
    "with open('./temp/array_times.pickle', 'rb') as handle:\n",
    "    array_times = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "# Change this to recalculate segmentation. Pay attention as it could take time. \n",
    "redo_segmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "# Prettier plots\n",
    "import seaborn as sns\n",
    "sns.set(#font='Palatino',\n",
    "        rc={\n",
    " 'axes.axisbelow': False,\n",
    " 'axes.edgecolor': 'k',\n",
    " 'axes.facecolor': 'None',\n",
    " 'axes.grid' : False,\n",
    " 'axes.spines.right': False,\n",
    " 'axes.spines.top': False,\n",
    " 'figure.facecolor': 'white',\n",
    " 'lines.solid_capstyle': 'round',\n",
    " 'patch.edgecolor': 'w',\n",
    " 'patch.force_edgecolor': True,\n",
    " 'xtick.bottom': True,\n",
    " 'xtick.direction': 'out',\n",
    " 'xtick.top': False,\n",
    " 'ytick.direction': 'out',\n",
    " 'ytick.left': True,\n",
    " 'ytick.right': False})\n",
    "\n",
    "# Vectorial plot\n",
    "import matplotlib_inline.backend_inline as backend_inline \n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "## Testing parallel loading of ZARR\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "def paral(func, lista, N, threads=True, processes=False):\n",
    "    if processes:\n",
    "        with ProcessPoolExecutor(max_workers=N) as executor:\n",
    "            results = executor.map(func, lista)\n",
    "        return list(results)\n",
    "    elif threads:\n",
    "        with ThreadPoolExecutor(max_workers=N) as executor:\n",
    "            results = executor.map(func, lista)\n",
    "        return list(results)\n",
    "\n",
    "## Testing parallel loading of ZARR\n",
    "def loadindex(index):\n",
    "    try:\n",
    "        return img[index][:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "## Visualization method\n",
    "def visualize_data(array_data, array_segments = None, array_times = None, cmap='crest'):\n",
    "    # Widget slider to browse the data\n",
    "    index = widgets.IntSlider(\n",
    "        value=5, min=0, max=array_data.shape[0] - 1, step=1, description=\"Index\"\n",
    "    )\n",
    "\n",
    "    # Other widget slider to browse the channels\n",
    "    channel = widgets.IntSlider(\n",
    "        value=5, min=0, max=array_data.shape[3] - 1, step=1, description=\"Channel\"\n",
    "    )\n",
    "\n",
    "    # Checkbox to display RGB (override the channel)\n",
    "    display_RGB = widgets.Checkbox(description=\"Display RGB\", value=False)\n",
    "\n",
    "    ui = widgets.HBox([index, channel, display_RGB])\n",
    "\n",
    "    # Widget interaction function\n",
    "    def anim(index_value, channel_value, display_RGB_value):\n",
    "        fig = plt.figure(figsize=(10,8))\n",
    "        if display_RGB_value:\n",
    "            plt.imshow( array_data[index_value, :, :, (3,2,1)].swapaxes(0,1).swapaxes(1, 2))\n",
    "        else:\n",
    "            plt.imshow(array_data[index_value, :, :, channel_value], cmap = cmap)\n",
    "        if array_segments is not None:\n",
    "            if np.sum(array_segments[index_value])>0:\n",
    "                plt.contour(array_segments[index_value], [0.5], colors='r')\n",
    "        if array_times is not None:\n",
    "            plt.title('Acquisition time: ' + str(array_times[index_value]))\n",
    "        else:\n",
    "            plt.title('Acquisition time: ' + str(df['beginposition'][index_value]))\n",
    "        plt.axis('off')\n",
    "        return\n",
    "\n",
    "    # Link widget and function\n",
    "    out = widgets.interactive_output(anim, {\"index_value\": index, 'channel_value': channel, 'display_RGB_value': display_RGB})\n",
    "\n",
    "    # Display result\n",
    "    return ui, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20648911",
   "metadata": {},
   "source": [
    "## Dependencies and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029088c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_segmentation(image):\n",
    "    image_normalized = image/np.max(image)\n",
    "    seg = morphological_chan_vese(image_normalized , num_iter= 200, init_level_set='disk', smoothing=2, lambda1 = 10., lambda2 = 1.)\n",
    "    return seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48335d",
   "metadata": {},
   "source": [
    "## Loading of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d314ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_segmentation():\n",
    "    # Segment all images in the dataset on channel 9 (# ! Takes ~1h to run) (B03 - B08) / (B03 + B08)\n",
    "    l_segmented_images = paral(apply_segmentation, array_data_cropped[:,:,:,9], 10) #array_data_cropped[:,:,:,9] #np.squeeze(ndwi_array)+1\n",
    "    array_segmented_images = np.array(l_segmented_images)\n",
    "    del l_segmented_images\n",
    "\n",
    "#     # Store result as it's pretty heavy to compute\n",
    "#     with open(r\"./data/segmentation.npy\", 'wb') as f:\n",
    "#         np.save(f, array_segmented_images)\n",
    "        \n",
    "if redo_segmentation == True:\n",
    "    calc_segmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32786c68",
   "metadata": {},
   "source": [
    "## Filter out bad-segments based on size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947913da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out segments that are 80% smaller than the main segment\n",
    "for index, segment in enumerate(array_segmented_images):\n",
    "    try:\n",
    "        cnts = cv2.findContours(segment.astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "        rect_areas = []\n",
    "        for c in cnts:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            rect_areas.append(w * h)\n",
    "        max_area = np.max(rect_areas)\n",
    "        for c in cnts:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cnt_area = w * h\n",
    "            if cnt_area < 0.2 * max_area:\n",
    "                segment[y:y + h, x:x + w] = 0\n",
    "        array_segmented_images[index] = segment\n",
    "        \n",
    "    except Exception as e:\n",
    "        #print(index, e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out segments out segments that are outside of the largest segment when the lake is the \n",
    "# fullest (among the first images, as it becomes empty afterwards)\n",
    "biggest_segment_index = np.argmax([np.sum(x) for x in array_segmented_images[:20]])\n",
    "biggest_segment = array_segmented_images[biggest_segment_index]\n",
    "for index, segment in enumerate(array_segmented_images):\n",
    "    segment_diff = biggest_segment - segment\n",
    "    segment[segment_diff < 0] = 0\n",
    "    array_segmented_images[index] = segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1c99e",
   "metadata": {},
   "source": [
    "## Filtering out based on water content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display distribution of intensity difference with 'pure' lake\n",
    "l_diff_mean_segments = [np.mean(array_data_cropped[index,:,:,9][segment==1])-np.mean(array_data_cropped[biggest_segment_index,:,:,9][biggest_segment==1]) if np.sum(segment)>0 else np.nan for index, segment in enumerate(array_segmented_images)]\n",
    "tresh = 1450\n",
    "\n",
    "def plot_segment_differences():\n",
    "    fig, ax = plt.subplots(1, figsize = (10,5))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.hist(l_diff_mean_segments, bins=100)\n",
    "    plt.ylim(0, 8)\n",
    "    plt.xlim(-100, 1600)\n",
    "    plt.xlabel(\"Segment mean intensity value difference w.r.t clean segment\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "    # Create one rectangle patch and add it to the plot\n",
    "    rect = patches.Rectangle((tresh, 0), 1600-tresh, 8, alpha = 0.3, facecolor=\"red\")\n",
    "    ax.add_patch(rect)\n",
    "    plt.title(\"Distribution of segment differences of intensity value w.r.t cleanest segment\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180334cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out segments that have an intensity which is significantly different from when the lake is the purest\n",
    "array_segmented_images = np.array([segment if (l_diff_mean_segments[index]< tresh and not np.isnan(l_diff_mean_segments[index])) else np.zeros_like(segment) for index, segment in enumerate(array_segmented_images)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb35fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation():\n",
    "    ui, out = visualize_data(array_data_cropped,  array_segments = array_segmented_images, array_times = array_times)\n",
    "    display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./temp/array_segmented_images.npy', array_segmented_images)\n",
    "\n",
    "# with open('./temp/array_segmented_times.pickle', 'wb') as handle:\n",
    "#     pickle.dump(array_segmented_times, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
